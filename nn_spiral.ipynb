{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# A bit of setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generateSpiralData():\n",
    "    '''\n",
    "    Generate spiral data for training\n",
    "    \n",
    "    N = 300, D = 2, K = 3 will generate dataSets contains 900 2D point.\n",
    "    900 2D points(D=2) are divided into 3 (K=3) classes, each classes contains\n",
    "    300 (N=300) points.\n",
    "    \n",
    "    dataSet is returned as X, y\n",
    "    X - pointsArray\n",
    "    y - classArray\n",
    "    '''\n",
    "    np.random.seed(0)\n",
    "    N = 300 # number of points per class\n",
    "    D = 2 # dimensionality\n",
    "    K = 3 # number of classes\n",
    "    X = np.zeros((N*K,D))\n",
    "    y = np.zeros(N*K, dtype='uint8')\n",
    "    for j in range(K):\n",
    "        ix = range(N*j,N*(j+1))\n",
    "        r = np.linspace(0.0,1,N) # radius\n",
    "        t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta\n",
    "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "        y[ix] = j\n",
    "    fig = plt.figure()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "    plt.xlim([-1,1])\n",
    "    plt.ylim([-1,1])\n",
    "    fig.savefig('spiralData.png')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def splitSpiralData(dataSet, labelSet, trainR = 0.6, valR = 0.2):\n",
    "    '''\n",
    "    Split data into traingSet, validationSet and testSet\n",
    "    \n",
    "    Given data and label array are random shuffled and divided\n",
    "    trainR=0.6, valR=0.2, dataSet= 100*2 array\n",
    "    trainData will be 60*2 array, validationdata will be 20*2 array and\n",
    "    testData will be 20*2 array.\n",
    "    \n",
    "    '''\n",
    "    numSamples = np.shape(dataSet)[0]\n",
    "    shuffledIndices = np.array(range(numSamples))\n",
    "    random.shuffle(shuffledIndices)\n",
    "    \n",
    "    numTrain = round(numSamples * trainR)\n",
    "    numVal   = round(numSamples * valR)\n",
    "    numTest  = numSamples - numTrain - numVal\n",
    "    \n",
    "    trainData    = dataSet[shuffledIndices[:numTrain]]\n",
    "    trainLabels  = labelSet[shuffledIndices[:numTrain]]\n",
    "    valData      = dataSet[shuffledIndices[numTrain:numTrain + numVal]]\n",
    "    valLabels    = labelSet[shuffledIndices[numTrain:numTrain + numVal]]\n",
    "    testData     = dataSet[shuffledIndices[numTrain + numVal:]]\n",
    "    testLabels   = labelSet[shuffledIndices[numTrain + numVal:]]\n",
    "    \n",
    "    return trainData, trainLabels, valData, valLabels, testData, testLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initWeightBias(wShape, bShape):\n",
    "    '''\n",
    "    Helper function to initilize weight and bias matrix\n",
    "    \n",
    "    wShape - Dimension of weight matrix, e.g. (2, 2) \n",
    "    bShape - Dimension of bias matrix\n",
    "    \n",
    "    '''\n",
    "    W = 0.01 * np.random.randn(*wShape)\n",
    "    b = 0.01 * np.zeros(bShape)\n",
    "    \n",
    "    return W,b    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hiddenLayer(X, W, b):        \n",
    "    # Forward propagation, calculate the value of hidden layer\n",
    "    #\n",
    "    # recall in class\n",
    "    # hidden_layer = ReLU(X * W1 + b1)\n",
    "    # output_layer = hidden_layer * W2 + b2    \n",
    "    #\n",
    "    # implement HINTs \n",
    "    # 1. ReLu(x) \n",
    "    #     np.maximum(0, x)\n",
    "    # 2. matrix multiply, A * B\n",
    "    #     np.dot(A, B)     \n",
    "    #\n",
    "    # ===== YOUR CODE STARTs =======   \n",
    "    hidden_layer = np.maximum(0, np.dot(X,W) + b)\n",
    "    \n",
    "\n",
    "    \n",
    "    # ===== YOUR CODE ENDs =======    \n",
    "    return hidden_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outputLayer(hidden_layer, W, b):\n",
    "    # Forward propagation, calculate the value of output layer\n",
    "    #\n",
    "    # recall in class\n",
    "    # hidden_layer = ReLU(X * W1 + b1)\n",
    "    # output_layer = hidden_layer * W2 + b2    \n",
    "    #\n",
    "    # ===== YOUR CODE STARTs =======   \n",
    "    output_layer = np.dot(hidden_layer, W) + b \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ===== YOUR CODE ENDs =======\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossEntropy(scores, actLabels):\n",
    "    '''\n",
    "    Helper function to calculate the cross-entropy\n",
    "    \n",
    "    scores    - the output layer matrix, predicted class label\n",
    "    actLabels - the actual class label\n",
    "    \n",
    "    e.g. There two points P1, P2 need to be classfied, the output\n",
    "    of our model might look like\n",
    "    scores    - [[0.02, 0.9, 1.1],      # point 1 score\n",
    "                 [0.05, 0.7, 0.2]]      # point 2 score\n",
    "                 \n",
    "    The probability of each point's class is\n",
    "    Prob1 - [0.1573, 0.3793, 0.4633]    # 0.3793 = e^0.9 / (e^0.02 + e^0.9 + e^1.1) \n",
    "    Prob2 - [0.2453, 0.4698, 0.2849]    \n",
    "\n",
    "    The actual label of two points\n",
    "    actLabels -  [1,\n",
    "                  2]\n",
    "                  \n",
    "    Cross-entropy of each point will be\n",
    "    L1 = -log( 0.3793 ) = 0.9693\n",
    "    L2 = -log( 0.2849 ) = 1.2556\n",
    "    \n",
    "    Output(probs, logprobs) will be \n",
    "    probs     = [Prob1,\n",
    "                 Prob2]\n",
    "    \n",
    "    logprobs  = [L1,    \n",
    "                 L2]\n",
    "\n",
    "    '''\n",
    "    numSamples = np.shape(actLabels)[0]\n",
    "    exp_scores = np.exp(scores)\n",
    "    probs      = exp_scores/ np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    logprobs   = -np.log(probs[range(numSamples),trainL])\n",
    "    \n",
    "    return probs, logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataLoss(Loss):\n",
    "    # Calculate the data loss from given cross entropy\n",
    "    #\n",
    "    # data_loss = (L1 + L2 + ... Ln) / numerOfExamples\n",
    "    #\n",
    "    # ===== YOUR CODE STARTs =======   \n",
    "    numSamples = np.shape(Loss)[0]\n",
    "    data_loss  = np.sum(Loss)/numSamples\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ===== YOUR CODE ENDs =======\n",
    "    return data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regLoss(regFactor, W1, W2):\n",
    "    # Calculate the regularization loss \n",
    "    #\n",
    "    # reg_loss = sum of weights' square\n",
    "    #\n",
    "    # ===== YOUR CODE STARTs =======   \n",
    "    reg_loss = 0.5*regFactor*np.sum(W1*W1) + 0.5*regFactor*np.sum(W2*W2)\n",
    "    \n",
    "    \n",
    "    # ===== YOUR CODE ENDs =======\n",
    "    return reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def trainNN(trainD, trainL, D=2, K=3, h=100, step_size=1e-0, reg=1e-3):\n",
    "    '''\n",
    "    Train 2 layer neural network\n",
    "    \n",
    "    D - input dimensions, e.g. for 2D points, D = 2\n",
    "    K - output dimensions, e.g. classify 3 classes, K = 2\n",
    "    h - number of neurons in hidden layer\n",
    "    step_size - training steps length\n",
    "    reg - constant for L2 regularization\n",
    "\n",
    "    Weight and bias of 2 layer neural network is returned\n",
    "    W1,b1,W2,b2\n",
    "    '''\n",
    "    numSamples = np.shape(trainD)[0]\n",
    "        \n",
    "    # init Weights and Bias\n",
    "    # You should initialize W1 W2 with small integer\n",
    "    # initialize b1 b2 with 0\n",
    "    #\n",
    "    # function initWeightBias could be used\n",
    "    # \n",
    "    # W1 - D * h matrix\n",
    "    # b1 - 1 * h vector\n",
    "    # W2 - h * K matrix\n",
    "    # b2 - 1 * K vector\n",
    "    #    \n",
    "    # ===== YOUR CODE STARTs =======   \n",
    "    W1,b1 = initWeightBias((D,h),(1,h))\n",
    "    W2,b2 = initWeightBias((h,K),(1,K))\n",
    "    \n",
    "\n",
    "    # ===== YOUR CODE ENDs =======\n",
    "\n",
    "    for i in range(10000):\n",
    "        hidden_layer = hiddenLayer(trainD, W1, b1) \n",
    "        output_layer = outputLayer(hidden_layer, W2, b2)\n",
    "        scores       = output_layer\n",
    "        \n",
    "        # Compute the cross entropy and loss\n",
    "        probs, logprobs = crossEntropy(scores, trainL)              \n",
    "        data_loss       = dataLoss(logprobs)         \n",
    "        reg_loss        = regLoss(reg, W1, W2)\n",
    "        loss            = data_loss + reg_loss\n",
    "   \n",
    "        if i%1000 == 0:\n",
    "            print(\"iter i %f, loss %f\" % (i, loss))\n",
    "            plotDataAndBoundary(trainD,trainL,W1,b1,W2,b2,fileName='spiral_' + str(i) + '.png')\n",
    "    \n",
    "        # compute the gradient on scores, check following article for details\n",
    "        # http://blog.csdn.net/yc461515457/article/details/51924604\n",
    "        dscores = probs\n",
    "        dscores[range(numSamples),trainL] -= 1 \n",
    "        dscores /= numSamples\n",
    "\n",
    "        # backward propagation of data_loss\n",
    "        dW2 = np.dot(hidden_layer.T, dscores)\n",
    "        db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "\n",
    "        dhidden = np.dot(dscores, W2.T)\n",
    "        dhidden[hidden_layer <= 0] = 0 # derivative of reLU\n",
    "        dW1 = np.dot(trainD.T, dhidden)\n",
    "        db1 = np.sum(dhidden, axis=0, keepdims=True)\n",
    "\n",
    "        # reg_loss\n",
    "        dW2 += reg* W2\n",
    "        dW1 += reg* W1\n",
    "\n",
    "        # update Weight and Bias\n",
    "        W1 += -step_size * dW1\n",
    "        b1 += -step_size * db1\n",
    "        W2 += -step_size * dW2\n",
    "        b2 += -step_size * db2\n",
    "    return W1,b1,W2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plotDataAndBoundary(X,y,W1,b1,W2,b2,h=0.02,fileName='spiralAndBoundary.png'):\n",
    "    '''\n",
    "    Show data and decision boundary of neural network\n",
    "    '''\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = np.dot(np.maximum(0, np.dot(np.c_[xx.ravel(), yy.ravel()], W1) + b1), W2) + b2\n",
    "    Z = np.argmax(Z, axis=1)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    fig = plt.figure()\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    fig.savefig(fileName)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X,y = generateSpiralData()\n",
    "trainD, trainL, valD, valL, testD, testL = splitSpiralData(X,y)\n",
    "W1,b1,W2,b2 = trainNN(trainD,trainL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# test on valDataSet\n",
    "valLayer1 = hiddenLayer(valD, W1, b1)\n",
    "valLayer2 = outputLayer(valLayer1, W2, b2)\n",
    "predicted_class = np.argmax(valLayer2, axis = 1)\n",
    "print('validation accuracy: %.4f' % (np.mean(predicted_class == valL)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot the resulting classifier\n",
    "plotDataAndBoundary(valD,valL,W1,b1,W2,b2,fileName='spiralVal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
